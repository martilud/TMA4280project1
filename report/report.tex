\documentclass[12pt]{article}
\author{Martin Ludvigsen}
\title{TMA4280 - Project 1}

\usepackage{amsmath}
\usepackage{graphicx}
\graphicspath{{figures/}}

\begin{document}
\maketitle
\section{Introduction}
The project was written in Fortran, using a home-brewed Makefile and Python for plotting. The organization of the folders
should make it obvious where the files are located. The project can be downloaded from github using this link:
\begin{equation*}
    \texttt{https://github.com/martilud/TMA4280project1.git}
\end{equation*}
Throughout the entire project, i used \texttt{REAL} instead of \texttt{DOUBLE PRECISION} variables, and used compiler flags to ensure double precision for both floats and integers.
This was somewhat inconsistent, as i had to use \texttt{MPI\_DOUBLE\_PRECISION} instead of \texttt{MPI\_REAL} later.

The objective of the project is to calculate $\pi$ using two formulae, rewritten slightly from the problem description. First, the simple, yet beautiful Riemann-Zeta/Basel problem formula
first proved by Euler:
\begin{equation}
    \lim_{n \rightarrow \infty} \sum_{i = 1}^n \frac{1}{i^2} = \frac{\pi^2}{6},
    \label{eq:zeta}
\end{equation}
and secondly, the slightly more complex, "original" Machin formula, based on the Taylor series expansion of $\text{arctan} x$:
\begin{equation}
    \lim_{n \rightarrow \infty} \sum_{i = 1}^n (-1)^{i-1} \frac{1}{2i-1}\left(4 \left(\frac{1}{5}\right)^{2i-1} - \left(\frac{1}{239}\right)^{2i-1}\right) = \frac{\pi}{4}.
    \label{eq:mach}
\end{equation}

\section{Question 1. Serial Implementation}
In both formulae, we can expect roundoff errors for large $i$. In double precision, the mantissa uses $52$ bits, meaning the smallest "distance" we can measure
between numbers is $2^{-52} \approx 2.22 \times 10^{-16}$. This is also called the precision of double precision numbers.
Note this is not the same as the smallest number we can represent in double precision. We can actually represent numbers as small as
$\pm 2.23 \times 10^{-308}$, but when we start doing mathematical operations, we make round off errors. 
This also means that the order of operations in our calculations actually matter, as floating point operations are not commutative.
Note that for \eqref{eq:mach}, it's much faster to calculate $\left(\frac{1}{5}\right)^{2i-1}$ by saving $\left(\frac{1}{5}\right)$ in a variable and multiplying it by 
$\left(\frac{1}{5}\right)^2$ each iteration instead of calculating it bottom up each iteration.
My implementation showed to be sufficiently numerically stable, as we will see later. 

\section{Question 2. Unit Test(s)}
A unit test is a fast test of our program. The purpose of a 
unit test is to check the logic in our code to ensure it runs correctly.
In larger programs, one usually runs unit tests on small parts of code
to ensure that every part works as intended. In our toy example, we only
have to check if the program actually runs, and returns something slightly logical.
For this, I could have written a separate Fortran program, bash script of some sort or used some unit testing software.

But before we write anything, what whould we test to ensure our code works correctly? For \eqref{eq:zeta}, we see that a partial sum will always be (up to floating point errors), between $1$ and
$\frac{\pi^2}{6}$. Thus we can check if the error in our calculated $\pi_n$, calculated as $|\pi - \pi_n|$, is somewhere between $1$ and $\pi - \sqrt{6}$.

Using similar logic for \eqref{eq:mach}
we see that the first term in the sum is $\frac{4}{5} - \frac{1}{239}$, and all subsequences should be closer to $\pi$ than this by the error bound provided by the
alternating series test (REFERANSE). Thus, we can check if the error is larger than $4 *(\frac{4}{5} - \frac{1}{239}) - \pi$, as no subsequence should have a higher error than this.  

When implementing, it proved to be simplest to just program the test into our original program, and use the command line to input if we want to test. This was mostly because bash scripts can't
handle floating point numbers and i did not want to bother linking different Fortran scripts together. The simplest solution is often the best solution.

We can then make a command in the Makefile to execute our unit test(s) easily, either by typing for example \texttt{make zeta0utest} to run the \texttt{zeta0} unit test or
\texttt{make utest} to run all unit tests. Figure \ref{fig:Q2} shows the output of our unit test(s). It works! 
\begin{figure}[!htb]
    \centering
    \caption{Result of running \texttt{make utest}}
    \includegraphics[width=\textwidth]{Screenshot2}
    \label{fig:Q2}
\end{figure}

\section{Question 3. Verification Test(s)}
Now that we know our programs work, we have to see if the mathematics behave nicely. For simplicity, this was also programmed directly into our existing program similarily to the Unit Test.
In our verification test, we check the error for many different $n$, and save the resulting error and the time it took calculate in a textfile. This can be executed similarily
to the unit test, just swap the word \texttt{utest} with \texttt{vtest}.

Results from running the verification tests are shown in figures \ref{fig:Convergence1} and \ref{fig:Time1}. 

\begin{figure}[!htb]
    \centering
    \caption{Convergence result of running \texttt{make vtest}}
    \includegraphics[width=\textwidth]{Convergence1}
    \label{fig:Convergence1}
\end{figure}

\begin{figure}[!htb]
    \centering
    \caption{Timing result of running \texttt{make vtest}}
    \includegraphics[width=\textwidth]{Time1}
    \label{fig:Time1}
\end{figure}
We see that the Machin formula quickly converges to a very low number, specifically $8.9 \times 10^{-16}$. 
This is obtained after only $16$ iterations, and subsequent iterations do not improve the accuracy of our estimate.
This is because of roundoff errors. Looking at equation \eqref{eq:mach} we see that the sixteenth term is $\frac{1}{31}((2.15 \times 10^{-22}) + (1.86 \times 10^{-74}))$. 
As i mentioned earlier, this can be represented as a floating point number, but the computer is unable to evaluate the sum of the two numbers correctly.
It is also completely unable to evaluate the number we obtain when we add this very small term to our sum variable. Thus, we get stuck at an error of $8.9 \times 10^{-16}$.

For the Riemann-Zeta formula, the convergence is slow, and we are unable to reach a good estimate of $\pi$ even after $2^{24} \approx 1.68 \times 10^7$ iterations. Note that
the first term where we approach the precision available to us is when $\frac{1}{i^2} \approx 10^{-16}$, meaning the $10^8$th iteration. 

Looking at the time the different foruma uses, we see that the Machin formula is vastly superior here as well. Ironically, there are some round-off errors in timing for very few iterations as well.
This is somewhat surprising, as the Riemann-Zeta formula is so much simpler. (MAYBE THIS WILL MAKE MORE SENSE WHEN WE LOOK INTO THE NUMBER OF FLOPS)

\section{Question 4. Data distribution}
Now onto some distributed parallell computing. This means that we have different processing units with their own memory, and we have to use a Message Passing Interface (MPI) to transfer
data between processes.
In our program, we have one process calculate each term of the sum, save it into a vector, distribute the vector to different processes and have each process calculate
their partial sums, before adding the partial sums together. This is a bad decision, because there is an obvious bottleneck. One of the main problems with high performance computing
are the different bottlenecks. Here, the bottleneck is that one process has to do a lot of work serially. Even worse, the amount of work that has to be done serially perfectly scales
with the workload. Amdahl's law then predicts an upper limit to the speedup we can achieve. The theoretical speedup can be written as
\begin{equation}
    S(s) = \frac{1}{(1-p) + p/s}
\end{equation}
where $s$ is the speedup achieved by the part of the program that is parallellizable, which is often assumed to be equal to the number of processing units, and $p$ is the portion of the 
program that has to be done serially. The point is that $S \le \frac{1}{1-p}$, meaning that if a large part of our program has to be done serially, we can only achieve a marginal speedup.

The solution would be to ensure that as much of the program as possible is done in parallell. This can be done by having each process calculate the terms in their partial sum, not saving it
in a vector and adding the terms before summing the different partial sums to the master process. Here, the only serial parts of the program is taking arguments from the command line
and the overhead from MPI. I guess the reason we don't do this is that our program is a good example of data-parallellism that MPI is most often used for.

I actually made a unit test for this part of the program as well, which splits the data using \texttt{MPI\_Scatter}, checks if the resulting subvectors match the original vector, 
which is transferred using $\texttt{MPI\_Bcast}$, and uses
\texttt{MPI\_Reduce} to check if any process had any erroneous data.

\section{Question 5. MPI Implementation}
We've already mentioned how the resulting program works, and we also use \texttt{MPI\_Reduce} here for the final summation of the different
partial sims. In addition we have to use \texttt{MPI\_Init}, 
\texttt{MPI\_Comm\_size}, \texttt{MPI\_Comm\_rank} and \texttt{MPI\_Finalize}, as we can't really do anything in MPI without invoking these. 
Most MPI programs can be made using the mentioned functions and \texttt{MPI\_Send} and \texttt{MPI\_Recv} (we did not need these as \texttt{MPI\_Scatter} was more convenient),
but there are virtually no limits to how fancy you can make your MPI program
by using more advanced MPI functions.

For timing we use the \texttt{MPI\_Wtime} function (????????????????????????????????)

\section{Question 6. More MPI analysis}

\section{Question 7. OpenMP implementation}

\section{Question 8. Hybrid MPI/OpenMP implementation}

\section{Question 9. Discussion}

\section{Question 10. Conclusion}

\section{References}
FIXX ME
https://en.wikipedia.org/wiki/Alternating\_series\_test
\end{document}
